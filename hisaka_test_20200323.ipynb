{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled79.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJJu5wPoiKAPetgRBd17It",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HisakaKoji/sentence-transformers/blob/master/hisaka_test_20200323.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eTLvwzf6pmz",
        "colab_type": "code",
        "outputId": "b8b98f61-cbfa-48cb-9917-fe49f01d2343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        }
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/sonoisa/sentence-transformers\n",
        "!cd sentence-transformers; pip install -r requirements.txt\n",
        "!wget -O sonobe-datasets-sentence-transformers-model.tar \"https://www.floydhub.com/api/v1/resources/JLTtbaaK5dprnxoJtUbBbi?content=true&download=true&rename=sonobe-datasets-sentence-transformers-model-2\"\n",
        "!tar -xvf sonobe-datasets-sentence-transformers-model.tar"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'sentence-transformers' already exists and is not an empty directory.\n",
            "Requirement already satisfied: transformers==2.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (4.38.0)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.18.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.2.5)\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.996.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (1.12.23)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (2.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (0.1.85)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r requirements.txt (line 7)) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0->-r requirements.txt (line 1)) (7.1.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.23 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->-r requirements.txt (line 1)) (1.15.23)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->-r requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->-r requirements.txt (line 1)) (0.9.5)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.23->boto3->transformers==2.3.0->-r requirements.txt (line 1)) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.23->boto3->transformers==2.3.0->-r requirements.txt (line 1)) (2.8.1)\n",
            "--2020-03-23 01:43:15--  https://www.floydhub.com/api/v1/resources/JLTtbaaK5dprnxoJtUbBbi?content=true&download=true&rename=sonobe-datasets-sentence-transformers-model-2\n",
            "Resolving www.floydhub.com (www.floydhub.com)... 104.26.0.30, 104.26.1.30, 2606:4700:20::681a:11e, ...\n",
            "Connecting to www.floydhub.com (www.floydhub.com)|104.26.0.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/tar]\n",
            "Saving to: ‘sonobe-datasets-sentence-transformers-model.tar’\n",
            "\n",
            "sonobe-datasets-sen     [     <=>            ] 422.28M  33.6MB/s    in 13s     \n",
            "\n",
            "2020-03-23 01:43:28 (32.5 MB/s) - ‘sonobe-datasets-sentence-transformers-model.tar’ saved [442788352]\n",
            "\n",
            "./\n",
            "./training_bert_japanese/\n",
            "./training_bert_japanese/0_BERTJapanese/\n",
            "./training_bert_japanese/0_BERTJapanese/added_tokens.json\n",
            "./training_bert_japanese/0_BERTJapanese/config.json\n",
            "./training_bert_japanese/0_BERTJapanese/pytorch_model.bin\n",
            "./training_bert_japanese/0_BERTJapanese/sentence_bert_config.json\n",
            "./training_bert_japanese/0_BERTJapanese/special_tokens_map.json\n",
            "./training_bert_japanese/0_BERTJapanese/tokenizer_config.json\n",
            "./training_bert_japanese/0_BERTJapanese/vocab.txt\n",
            "./training_bert_japanese/1_Pooling/\n",
            "./training_bert_japanese/1_Pooling/config.json\n",
            "./training_bert_japanese/config.json\n",
            "./training_bert_japanese/modules.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LdiGS3_7FfC",
        "colab_type": "code",
        "outputId": "35ba23c4-5df8-4328-9a79-10ca22e49e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd sentence-transformers"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/sentence-transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzwaFQcF7HCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "model_path = \"/content/training_bert_japanese\"\n",
        "model = SentenceTransformer(model_path, show_progress_bar=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcSVgPsh7K9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vnt7nvs7UxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('input_spot.txt',header = None)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld0LAJ3m8JOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.rename(columns={0: 'description'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USBo7R1D5uw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_name = pd.read_csv('name_spot.txt',header = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC7fc42t8Poz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_name = df_name.rename(columns={0: 'name'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65ezq5zl6iOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_comb = pd.concat([df_name,df], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBJXHrll96ZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_comb = df_comb.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMeocPSv7K_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "918f3295-89fe-4fe5-e5bc-f611d89741d0"
      },
      "source": [
        "df_comb.columns"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['name', 'description'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfrCgcps7br3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = df_comb['description'].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUmCZ-Gx7g2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_vectors = model.encode(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLtBftAN8vV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_name = df_comb['name'].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwfKoVBh7yYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "num_clusters = 8\n",
        "clustering_model = KMeans(n_clusters=num_clusters)\n",
        "clustering_model.fit(sentence_vectors)\n",
        "cluster_assignment = clustering_model.labels_\n",
        "\n",
        "clustered_sentences = [[] for i in range(num_clusters)]\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    clustered_sentences[cluster_id].append(sentences_name[sentence_id][:10])\n",
        "\n",
        "for i, cluster in enumerate(clustered_sentences):\n",
        "    print(\"Cluster \", i+1)\n",
        "    print(cluster)\n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P333vaBd6Kzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_queries = pd.read_csv('keyword.txt',header = None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIJoqeDa8KLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.spatial\n",
        "\n",
        "queries = ['美術館', 'グルメ', 'スポーツ大会', '子供がはしゃげる','ごはん']\n",
        "queries = df_queries[0].values.tolist()\n",
        "query_embeddings = model.encode(queries)\n",
        "\n",
        "closest_n = 5\n",
        "for query, query_embedding in zip(queries, query_embeddings):\n",
        "    distances = scipy.spatial.distance.cdist([query_embedding], sentence_vectors, metric=\"cosine\")[0]\n",
        "\n",
        "    results = zip(range(len(distances)), distances)\n",
        "    results = sorted(results, key=lambda x: x[1])\n",
        "\n",
        "    print(\"\\n\\n======================\\n\\n\")\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
        "\n",
        "    for idx, distance in results[0:closest_n]:\n",
        "        print(sentences_name[idx].strip(), \"(Score: %.4f)\" % (distance / 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VG5Ty2PA_TZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "399bd43d-7f78-45c4-a279-2e0c526673ee"
      },
      "source": [
        "%load_ext tensorboard\n",
        "import os\n",
        "logs_base_dir = \"runs\"\n",
        "os.makedirs(logs_base_dir, exist_ok=True)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbPTJ-nnBA3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorboard as tb\n",
        "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
        "\n",
        "summary_writer = SummaryWriter()\n",
        "summary_writer.add_embedding(mat=np.array(sentence_vectors), metadata=sentences_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydYLaWoKBCOI",
        "colab_type": "code",
        "outputId": "8e8614ca-f2db-4bb2-b11f-ccafba86a67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 1265), started 0:00:47 ago. (Use '!kill 1265' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "  (async () => {\n",
              "      const url = await google.colab.kernel.proxyPort(6006, {\"cache\": true});\n",
              "      const iframe = document.createElement('iframe');\n",
              "      iframe.src = url;\n",
              "      iframe.setAttribute('width', '100%');\n",
              "      iframe.setAttribute('height', '800');\n",
              "      iframe.setAttribute('frameborder', 0);\n",
              "      document.body.appendChild(iframe);\n",
              "  })();\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhgZhlUoGI1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill 1227"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}